{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import roman\n",
    "import os\n",
    "import csv\n",
    "from treatise_reference_data import *\n",
    "from master_function_list import ultimateParser as uP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the paper object. The idea is that we'll be passing into the single file processing function a PDF. That PDF will get turned into a text file with no white space. It's that text file that will be passed here. \n",
    "\n",
    "We can call that our Paper object for our purposes here. We want it to have a file name and containers for cites tied to different searches along with the functions to execute different searches. Finally we also want it to be able to generate a total scoring output for all citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paper:\n",
    "    def __init__(self, txt_file_name):\n",
    "        self.name = txt_file_name\n",
    "        self.nortonCites = []\n",
    "        self.sbnCites = []\n",
    "        self.rawParenthesesCapture = []\n",
    "        self.otherCites = []\n",
    "        \n",
    "    def NortonSearch(self):\n",
    "        citationCounter = 0 #citation counter to be used in numbering citations\n",
    "        #create the citation search object\n",
    "        #search pattern is\n",
    "##        Capture Abstract cites with optional dash additions\n",
    "##        Capture Appendix cites with optional dash additions\n",
    "##        Capture Main body cites as follows:\n",
    "##            Book. (capture both roman and arabic numeral versions)\n",
    "##            Part. (capture both roman (capitalized and not) and arabic numerals)\n",
    "##            Section (I left of the '.' here to be able to capture citations that are only Book.Part.Section with no paragraph citation)\n",
    "##            optional .Paragraph(s with optional dash separator for a range of paragraphs\n",
    "        nortonPattern = re.compile(\"\"\"  T*Abs\\d+\n",
    "                                            ([-–—]\\d{1,2}){0,1}|\n",
    "                                        T*App\\d+\n",
    "                                            ([-–—]\\d{1,2}){0,1}|\n",
    "                                        ((I{1,3}|[123])\\.)\n",
    "                                        (([i]{1,3}|IV|[I]{1,3}|[1-4])\\.)\n",
    "                                        (\\d{1,2})\n",
    "                                        (\\.[1-9]\\d{0,2}\n",
    "                                            ([-–—]\\d{1,2}){0,1}\n",
    "                                        ){0,1}\"\"\", re.X)\n",
    "        #make the text of the paper accessible and generate the match objects\n",
    "        paper_to_search = open(self.name, \"r\")\n",
    "        text_to_search = paper_to_search.readline()\n",
    "        paper_to_search.close()\n",
    "        matchObjects = nortonPattern.finditer(text_to_search)\n",
    "        #create a citation for each match object\n",
    "        for match in matchObjects:\n",
    "            citationCounter +=1\n",
    "            citationObject = Citation(self.name, citationCounter, match.group())\n",
    "            citationObject.startPoint = match.start()\n",
    "            citationObject.endPoint = match.end()\n",
    "            citationObject.search_term = match.re\n",
    "            self.nortonCites.append(citationObject)\n",
    "        if len(self.nortonCites) == 0:\n",
    "            pass\n",
    "    \n",
    "    def SbnSearch(self):\n",
    "        citationCounter = 0 #citation counter to be used in numbering citations\n",
    "        #create the citation search object\n",
    "##        the search pattern this time is to start with SBN\n",
    "##        then cover page numbers (I got rid of 0 as a starting point because a file happened to have a weird SBN0 followed by a long string of numbers\n",
    "##        next I have an optional dash and comma separator that can be repeated to capture the multiple pages and ranges that get cited\n",
    "##        this will require some cleaning because sometimes you get a random 'i' following the comma\n",
    "        sbnPattern = re.compile(\"\"\" (?<!I)\n",
    "                                    (SBN)\n",
    "                                    ([1-9]\\d+|[xvi]+|[XVI]+)\n",
    "                                    ([-–—,](\\d+|[xvi]+|[XVI]+))*\"\"\", re.X)\n",
    "        #make the text of the paper accessible and generate the match objects\n",
    "        paper_to_search = open(self.name, \"r\")\n",
    "        text_to_search = paper_to_search.readline()\n",
    "        paper_to_search.close()\n",
    "        matchObjects = sbnPattern.finditer(text_to_search)\n",
    "        #create a citation for each match object\n",
    "        for match in matchObjects:\n",
    "            citationCounter +=1\n",
    "            citationObject = Citation(self.name, citationCounter, match.group())\n",
    "            citationObject.startPoint = match.start()\n",
    "            citationObject.endPoint = match.end()\n",
    "            citationObject.search_term = match.re\n",
    "            self.sbnCites.append(citationObject)\n",
    "        if len(self.sbnCites) == 0:\n",
    "            pass\n",
    "    \n",
    "    def parenthesesCapture(self):\n",
    "        citationCounter = 0 #citation counter to be used in numbering citations\n",
    "        #create the citation search object\n",
    "        #This idea behind this search string is to get anything in parentheses with the following structure:\n",
    "            #First, it can optionally start with either a 'T', 'THN', 'Treatise', or 'Hume'\n",
    "            #Second, there can be a run of some intervening text but not a close parens or any numbers\n",
    "            #Third, we get a page number citation with an optional p, p., or pp.\n",
    "            #fourth, we get up to a three digit page number or range of up to 3 digit page numbers in either\n",
    "                #roman or arabic numerals\n",
    "            #The only thing I haven't figured out how to capture yet is a brief comment that appears in a few\n",
    "            #cases where the authro says something like, 'my emphases' or 'italics mine'. I think that might\n",
    "            #require a different search with a more restrictive start to the parentheses\n",
    "        pattern = re.compile('\\((T|THN|Treatise|Hume)*([A-Z]|[a-z]|[,.])*(p*\\.{0,1}(\\d{1,3}|[xvi]+|[XVI]+)([-–—,](\\d+|[xvi]{1,5}|[XVI]{1,5}))*)\\)')\n",
    "        #make the text of the paper accessible and generate the match objects\n",
    "        paper_to_search = open(self.name, \"r\")\n",
    "        text_to_search = paper_to_search.readline()\n",
    "        paper_to_search.close()\n",
    "        matchObjects = pattern.finditer(text_to_search)\n",
    "        #create a citation for each match object\n",
    "        for match in matchObjects:\n",
    "            citationCounter +=1\n",
    "            citationObject = Citation(self.name, citationCounter, match.group())\n",
    "            citationObject.startPoint = match.start()\n",
    "            citationObject.endPoint = match.end()\n",
    "            citationObject.search_term = match.re\n",
    "            self.rawParenthesesCapture.append(citationObject)\n",
    "        if len(self.rawParenthesesCapture) == 0:\n",
    "            pass\n",
    "    \n",
    "    def otherSearch(self, search_term):\n",
    "        citationCounter = 0 #citation counter to be used in numbering citations\n",
    "        #create the citation search object\n",
    "        pattern = re.compile(search_term)\n",
    "        #make the text of the paper accessible and generate the match objects\n",
    "        paper_to_search = open(self.name, \"r\")\n",
    "        text_to_search = paper_to_search.readline()\n",
    "        paper_to_search.close()\n",
    "        matchObjects = pattern.finditer(text_to_search)\n",
    "        #create a citation for each match object\n",
    "        for match in matchObjects:\n",
    "            citationCounter +=1\n",
    "            citationObject = Citation(self.name, citationCounter, match.group())\n",
    "            citationObject.startPoint = match.start()\n",
    "            citationObject.endPoint = match.end()\n",
    "            citationObject.search_term = match.re\n",
    "            self.otherCites.append(citationObject)\n",
    "        if len(self.otherCites) == 0:\n",
    "            pass\n",
    "    \n",
    "    def calculate_raw_score_sheet(self):\n",
    "        #gather all the citations\n",
    "        master_citation_list = []\n",
    "        for citation in self.nortonCites:\n",
    "            master_citation_list.append(citation)\n",
    "        for citation in self.sbnCites:\n",
    "            master_citation_list.append(citation)\n",
    "        for citation in self.rawParenthesesCapture:\n",
    "            master_citation_list.append(citation)\n",
    "        for citation in self.otherCites:\n",
    "            master_citation_list.append(citation)\n",
    "        \n",
    "        #turn each citation into a list of pairs\n",
    "        master_scoring_list = []\n",
    "        for citation in master_citation_list:\n",
    "            if citation.cleanedCitation != \"\":\n",
    "                try:\n",
    "                    for pair in uP(citation.cleanedCitation):\n",
    "                        #these pairs are (chapter, weight)\n",
    "                        master_scoring_list.append(pair)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(pair, \"generated an error calculating raw_score_sheet while running through uP\")\n",
    "                    pass\n",
    "                \n",
    "        #create a blank scoring sheet:\n",
    "        score_sheet = {}\n",
    "        for para in treatise_paragraph_list:\n",
    "            score_sheet[para] = 0\n",
    "        \n",
    "        #update score_sheet from master_score list\n",
    "        for pair in master_scoring_list:\n",
    "            try:\n",
    "                score_sheet[pair[0]] += pair[1]\n",
    "            except Exception as error:\n",
    "                print(error)\n",
    "                print(pair[0], 'generated a key error when trying to update the score sheet')\n",
    "                pass\n",
    "        \n",
    "        return score_sheet\n",
    "    \n",
    "    def make_csv_raw_score(self):\n",
    "        out_data = self.calculate_raw_score_sheet()\n",
    "        output_file = open(self.name[:-4]+\".csv\", \"w\")\n",
    "        csv_writer = csv.writer(output_file)\n",
    "        for pair in out_data.items():\n",
    "            csv_writer.writerow(pair)\n",
    "        output_file.close()\n",
    "        print('raw score sheet csv generated')\n",
    "    \n",
    "    def relative_score_sheet(self):\n",
    "        raw_score = self.calculate_raw_score_sheet()\n",
    "        total_score = 0\n",
    "        for para in raw_score.keys():\n",
    "            if raw_score[para] > 0:\n",
    "                total_score += raw_score[para]\n",
    "        relative_score_sheet = {}\n",
    "        for para in raw_score.keys():\n",
    "            if raw_score[para] > 0:\n",
    "                relative_score = 100*round(raw_score[para]/total_score,5)\n",
    "                relative_score_sheet[para] = relative_score\n",
    "            else:\n",
    "                relative_score_sheet[para] = raw_score[para]\n",
    "                \n",
    "        return relative_score_sheet\n",
    "    \n",
    "    def make_csv_relative_score(self):\n",
    "        out_data = self.relative_score_sheet()\n",
    "        output_file = open(self.name[:-4]+\"-relative-score.csv\", \"w\")\n",
    "        csv_writer = csv.writer(output_file)\n",
    "        for pair in out_data.items():\n",
    "            csv_writer.writerow(pair)\n",
    "        output_file.close()\n",
    "        print('relative score sheet csv generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's work with the Citation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Citation:\n",
    "    def __init__(self, paper_name, order_num, search_result):\n",
    "        self.order = order_num\n",
    "        self.paper = paper_name\n",
    "        self.search_term = \"\"\n",
    "        self.citationScores = []\n",
    "        self.startPoint = 0\n",
    "        self.endPoint = 0\n",
    "        self.rawCitationText = search_result\n",
    "        self.precedingText = \"\"\n",
    "        self.trailingText = \"\"\n",
    "        self.cleanedCitation = \"\"\n",
    "\n",
    "    #this function pulls a given number of characters from before the citation starts up to the start\n",
    "    #of the citation\n",
    "    def FindPrecedingText(self, num_chars):\n",
    "        #open the paper file\n",
    "        paper_file = open(self.paper, \"r\")\n",
    "        text_to_use = paper_file.readline()\n",
    "        paper_file.close()\n",
    "        #generate the buffer to get the appropriate slice in case it's around an edge of teh string\n",
    "        buffer = self.startPoint - num_chars\n",
    "        #set the proper text in the Citation\n",
    "        if self.startPoint == 0:\n",
    "            self.precedingText = ''\n",
    "        elif buffer >= 0:\n",
    "            self.precedingText = text_to_use[buffer:self.startPoint]\n",
    "        elif buffer < 0:\n",
    "            self.precedingText[:self.startPoint]\n",
    "\n",
    "    #this function pulls a given number of characters from the end of the citation going forward\n",
    "    def FindTrailingText(self, num_chars):\n",
    "        #open the paper file\n",
    "        paper_file = open(self.paper, \"r\")\n",
    "        text_to_use = paper_file.readline()\n",
    "        paper_file.close()\n",
    "        #generate the buffer to get the appropriate slice in case it's around an edge of the string\n",
    "        buffer = len(text_to_use) - (self.endPoint + num_chars)\n",
    "        #set the proper text in the Citation\n",
    "        if buffer == 0:\n",
    "            self.trailingText = \"\"\n",
    "        elif buffer > 0:\n",
    "            self.trailingText = text_to_use[self.endPoint:(self.endPoint + num_chars)]\n",
    "        elif buffer < 0:\n",
    "            self.trailingText = text_to_use[self.endPoint:]\n",
    "\n",
    "    #this function takes an integer as input and runs the previous two functions\n",
    "    def PopulateSurroundingTexts(self, num_chars):\n",
    "        self.FindPrecedingText(num_chars)\n",
    "        self.FindTrailingText(num_chars)\n",
    "\n",
    "    def calculateScore(self):\n",
    "        self.citationScores = uP(self.cleanedCitation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's test this out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paper = \"search_texts/533Cottrell.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Paper(test_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.NortonSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cite in test.nortonCites:\n",
    "    cite.cleanedCitation = cite.rawCitationText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw score sheet csv generated\n"
     ]
    }
   ],
   "source": [
    "test.make_csv_raw_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative score sheet csv generated\n"
     ]
    }
   ],
   "source": [
    "test.make_csv_relative_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so, so far the process of this function is something like:\n",
    "\n",
    "1. Create Paper Object\n",
    "2. Conduct searches\n",
    "3. For each Citation in all of the different citations we need to appropriately convert the .rawCitationText to .cleanedCitation\n",
    "4. Generate outputs we're interested in:\n",
    "    A. For further data processing we're interested in relative and perhaps raw scoring data, returned not in the form of csv data but of a dictionary/list.\n",
    "    B. For visualization we're probably just interested in relative citation csv data.\n",
    "   \n",
    "5. I think it's probably best to have the function return a dictionary/JSON object:\n",
    "    TotalCitationCount: INT\n",
    "    RelativeCitationData: Para/Score dictionary\n",
    "    RawCitationData: Para/score dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractCitationDataFromSinglePaper(file_in):\n",
    "    #generate the paper object\n",
    "    paper_obj = Paper(file_in)\n",
    "   \n",
    "    #conduct the searches\n",
    "    paper_obj.NortonSearch()\n",
    "    paper_obj.SbnSearch()\n",
    "    paper_obj.parenthesesCapture()\n",
    "    \n",
    "    #clean the citations\n",
    "    for citation in paper_obj.nortonCites:\n",
    "        citation.cleanedCitation = citation.rawCitationText\n",
    "    for citation in paper_obj.sbnCites:\n",
    "        cleanedCitation = cite.rawCitationText[3:]\n",
    "    \n",
    "    #this is a temporary check to get some of the easy citations we know are to treatise pages\n",
    "    #we'll use a counter to see how many clean cites we get\n",
    "    clean_parens_counter = 0\n",
    "    num_check = re.compile('(\\d{1,3})+([-–—,](\\d{1,3}))*')\n",
    "    for citation in paper_obj.rawParenthesesCapture:\n",
    "        #first check if the citation starts with a T\n",
    "        if citation.rawCitationText[1] == \"T\":\n",
    "           #second check if the T is followed by a page number\n",
    "            if num_check.search(citation.rawCitationText) != None:\n",
    "                #print('found a T cite with a page num in', paper)\n",
    "                pageNum = num_check.search(citation.rawCitationText).group()\n",
    "                citation.cleanedCitation = pageNum\n",
    "                clean_parens_counter += 1\n",
    "\n",
    "    #generate the raw citation data for the paper:\n",
    "    raw_score_sheet = paper_obj.calculate_raw_score_sheet()\n",
    "    \n",
    "    #generate the relative citation data for the paper:\n",
    "    relative_score_sheet = paper_obj.relative_score_sheet()\n",
    "    \n",
    "    #output the csv of relative citation \n",
    "    paper_obj.make_csv_relative_score()\n",
    "    \n",
    "    #create the output dictionary\n",
    "    od = {\n",
    "        'TotalCites': len(paper_obj.nortonCites)+len(paper_obj.sbnCites)+clean_parens_counter,\n",
    "        'RelativeCitationData': relative_score_sheet,\n",
    "        'RawCitationData': raw_score_sheet\n",
    "    }\n",
    "    \n",
    "    #return the output dictionary\n",
    "    return od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative score sheet csv generated\n"
     ]
    }
   ],
   "source": [
    "test_single = extractCitationDataFromSinglePaper(test_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.183"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_single['RawCitationData']['App.10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
